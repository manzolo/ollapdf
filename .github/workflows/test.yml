name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Cache Ollama models
      uses: actions/cache@v3
      with:
        path: ${{ github.workspace }}/ollama_data
        key: ${{ runner.os }}-ollama-phi

    - name: Set OLLAMA_MODEL_NAME for app service
      run: echo "OLLAMA_MODEL_NAME=phi" >> $GITHUB_ENV

    - name: Docker build
      run: docker compose -f docker-compose.yml -f docker-compose.cpu.yml build
      
    - name: Clean Docker
      run: docker builder prune -f && docker system prune -f

    - name: Pull Ollama base image
      run: docker pull ollama/ollama

    - name: Run temporary Ollama container to pre-pull phi model
      run: |
        docker run -d -p 11434:11434 --name temp-ollama -v ${{ github.workspace }}/ollama_data:/root/.ollama ollama/ollama
        ./wait-for-it.sh localhost:11434 --timeout=120 # Wait for temp ollama to be ready
        docker exec temp-ollama ollama pull phi
        docker stop temp-ollama
        docker rm temp-ollama
      
    - name: Start services (CPU)
      run: docker compose -f docker-compose.yml -f docker-compose.cpu.yml up -d

    - name: Wait for Ollama to be ready
      run: |
        ./wait-for-it.sh localhost:11434 --timeout=120





    - name: Wait for Streamlit app to be ready
      run: |
        ./wait-for-it.sh localhost:8501 --timeout=60
        echo "Giving Streamlit app more time to initialize..."
        sleep 30

    - name: Run RAG system test
      run: python test_rag.py

    - name: Stop services
      if: always()
      run: make down

    - name: Clean up Docker resources (after)
      if: always()
      run: docker system prune -a -f --volumes
